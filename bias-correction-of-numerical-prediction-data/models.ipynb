{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c54c1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "21b8955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1e11be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0a2ddd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bias_correction_ucl.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "data = data[data['Next_Tmax'].notnull() & data['Next_Tmin'].notnull()]\n",
    "data = data[data['Date'].notnull() & data['station'].notnull()]\n",
    "data = data[data['LDAPS_Tmax_lapse'].notnull() & data['LDAPS_Tmin_lapse'].notnull()]\n",
    "\n",
    "y_Tmax = data['Next_Tmax']\n",
    "y_Tmin = data['Next_Tmin']\n",
    "X = data.drop(['Next_Tmax', 'Next_Tmin'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1197bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y_Tmax, test_size=0.2, shuffle=True, random_state=random_state)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fe42b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingDataRowsDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        if cols is None:\n",
    "            cols = []\n",
    "        self.cols = cols\n",
    "        self.predicate = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if any([v not in X.columns for v in self.cols]):\n",
    "            raise Exception(\"Wrong column name provided\")\n",
    "        self.predicate = X[self.cols].notnull().all(axis='columns')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.predicate is None:\n",
    "            raise Exception(\"Have not been fed before transformation\")\n",
    "        if y:\n",
    "            return X[self.predicate], y[self.predicate]\n",
    "        return X[self.predicate]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "08236438",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = make_pipeline(\n",
    "#     MissingDataRowsDropper(cols=['station', 'Date']), \n",
    "    make_column_transformer(\n",
    "         (SimpleImputer(strategy='median'), ['Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin',\n",
    "       'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS',\n",
    "       'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4',\n",
    "       'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'Next_Tmax',\n",
    "       'Next_Tmin'])\n",
    "    ),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f975b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, to_predict):\n",
    "        if to_predict not in ['Next_Tmax', 'Next_Tmin']:\n",
    "            raise Exception('Unknown prediction type')\n",
    "        self.to_predict = to_predict\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.to_predict == 'Next_Tmax':\n",
    "            return X['LDAPS_Tmax_lapse']\n",
    "        else:\n",
    "            return X['LDAPS_Tmin_lapse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fa33ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9e9d51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6889e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "{'regressor__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessing), \n",
    "    ('regressor', Lasso())\n",
    "])\n",
    "params = {\n",
    "    'regressor__alpha': [1e-5, 1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=params,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    cv=k_fold\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "models['LR'] = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dda78f",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "054d2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "34920067",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['base_model'] = BaseModel('Next_Tmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "11c3678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "mean_squared_error: 2.0281103717201048e-07\n",
      "base_model\n",
      "mean_squared_error: 3.6321580125711477\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    print(f'mean_squared_error: {mean_squared_error(model.predict(X_test), y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac3afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
