{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jepq8kEPFTF2",
        "outputId": "f2b3ca5f-9b08-47d6-e48c-46b47dd86910"
      },
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scikit-learn-0.22.2.post1:\n",
            "  Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 64.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rVEJa94FeZE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWaahxWBFgcE"
      },
      "source": [
        "import os\n",
        "TITANIC_PATH = ''#os.path.join(\"datasets\", \"titanic\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_7H9Fm2FkBx"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
        "    csv_path = os.path.join(titanic_path, filename)\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0kVhRVFnU-"
      },
      "source": [
        "train_data = load_titanic_data(\"train.csv\")\n",
        "test_data = load_titanic_data(\"test.csv\")"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTLBkpGwSAuZ",
        "outputId": "dab67ede-2de1-4d90-dbfb-cf819d6535fc"
      },
      "source": [
        "train_target = train_data['Survived']\n",
        "train_data.drop('Survived', axis=1, inplace=True)\n",
        "train_data[:5], train_target[:5]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   PassengerId  Pclass  ... Cabin Embarked\n",
              " 0            1       3  ...   NaN        S\n",
              " 1            2       1  ...   C85        C\n",
              " 2            3       3  ...   NaN        S\n",
              " 3            4       1  ...  C123        S\n",
              " 4            5       3  ...   NaN        S\n",
              " \n",
              " [5 rows x 11 columns], 0    0\n",
              " 1    1\n",
              " 2    1\n",
              " 3    1\n",
              " 4    0\n",
              " Name: Survived, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82PpvASZKTwO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm7viY2mDhxV"
      },
      "source": [
        "train_data, validate_data, train_target, validate_target = train_test_split(train_data, train_target, test_size=0.2)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00DpPa6VM3H1",
        "outputId": "4ed339e7-c40e-453f-a417-bf19e01cad4a"
      },
      "source": [
        "train_data.shape, validate_data.shape, test_data.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((712, 11), (179, 11), (418, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCx7Ptzydomf",
        "outputId": "0b6592cd-f51e-4449-c0be-a7e8c0e6d1f4"
      },
      "source": [
        "(train_target == 1).sum() / train_target.size, (validate_target == 1).sum() / validate_target.size"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3890449438202247, 0.36312849162011174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APiiPhW4dmKv"
      },
      "source": [
        ""
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw91rduzFpHb"
      },
      "source": [
        "import re\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from collections import Counter"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qmQSCgaF0Gu"
      },
      "source": [
        "class AdditionalCollumnsAdder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self, features):\n",
        "    self.features = features\n",
        "    self.titles = None\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    counts = Counter([self.get_title(v) for v in X['Name']])\n",
        "    title_categoriess = sorted(set(self.get_title(v) for v in X['Name']), key=counts.get, reverse=True)\n",
        "    self.titles = {t: i for i, t in enumerate(title_categoriess)}\n",
        "    # print(self.titles)\n",
        "    return self\n",
        "\n",
        "  def transform(self, X_org, y=None):\n",
        "    X = X_org.copy()\n",
        "    if 'NameParts' in self.features:\n",
        "      X['NameParts'] = [len(v.split(' ')) for v in X['Name']]\n",
        "    if 'Title' in self.features:\n",
        "      if not self.titles:\n",
        "        raise 'Adder has to be fitted before transofrming'\n",
        "      X['Title'] = [\n",
        "                    self.titles[self.get_title(v)] \n",
        "                    if self.get_title(v) in self.titles.keys() \n",
        "                    else len(self.titles) \n",
        "                    for v in X['Name']\n",
        "                    ]\n",
        "    if 'Comrades' in self.features:\n",
        "      X['Comrades'] = [0 if v == 0 else (1 if v < 5 else 2) for v in X['SibSp'] + X['Parch']]\n",
        "    if 'CabinLvl' in self.features:\n",
        "      cabin = [re.sub('\\d', '', v)[0] if type(v) == str else 'H' for v in X['Cabin']]\n",
        "      X['CabinLvl'] = [ord(v) for v in cabin]\n",
        "    if 'Social' in self.features:\n",
        "      X['Social'] = [\n",
        "                     0 if age < 17\n",
        "                     else 1 if sex == 'Female' \n",
        "                     else 2 \n",
        "                     for age, sex in zip(X['Age'], X['Sex'])\n",
        "                     ]\n",
        "    return pd.DataFrame(X)\n",
        "\n",
        "\n",
        "  def get_title(self, v):\n",
        "    return re.search('(\\w+)\\.', v)[0]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdQLdryoGfwB"
      },
      "source": [
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "  most_frequent = None\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    self.most_frequent = pd.Series([X[c].value_counts().idxmax() for c in X], \n",
        "                              index=X.columns)\n",
        "    return self\n",
        "\n",
        "  def transform(self, X_org, y=None):\n",
        "    if self.most_frequent is None:\n",
        "      raise 'Imputer have to be fited previously'\n",
        "    X = X_org.copy()\n",
        "    return X.fillna(self.most_frequent)\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FM_9tsQF0i7"
      },
      "source": [
        "# num_cols_ex = [v for v in make_column_selector(dtype_include=np.number)(train_data) if v != 'PassengerId']\n",
        "# print(num_cols_ex)\n",
        "\n",
        "# transformer = Pipeline([\n",
        "#                         ('imputer', SimpleImputer(strategy='median'))\n",
        "# ])\n",
        "\n",
        "# num_pipeline = ColumnTransformer([('numerical', transformer, num_cols_ex)], remainder='drop')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RatfUejqGFAA",
        "outputId": "efc92b92-27a3-4d38-8f0c-07bb76a11189"
      },
      "source": [
        "cat_pipeline = ColumnTransformer(\n",
        "    [\n",
        "    #  ('one_hot_encoding', ohe_pipeline, ['Sex', 'Embarked']),\n",
        "     ('Sex_encoding', \n",
        "      Pipeline([('missing', MostFrequentImputer()), ('lab', OrdinalEncoder())]),\n",
        "      ['Sex']),\n",
        "     ('Embarked_encoding', \n",
        "      Pipeline([\n",
        "                ('missing', MostFrequentImputer()), \n",
        "                ('lab', OrdinalEncoder(categories=[['S', 'C', 'Q']]))\n",
        "                ]), \n",
        "      ['Embarked'])\n",
        "     ], \n",
        "     remainder='drop')\n",
        "cat_pipeline"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('Sex_encoding',\n",
              "                                 Pipeline(steps=[('missing',\n",
              "                                                  MostFrequentImputer()),\n",
              "                                                 ('lab', OrdinalEncoder())]),\n",
              "                                 ['Sex']),\n",
              "                                ('Embarked_encoding',\n",
              "                                 Pipeline(steps=[('missing',\n",
              "                                                  MostFrequentImputer()),\n",
              "                                                 ('lab',\n",
              "                                                  OrdinalEncoder(categories=[['S',\n",
              "                                                                              'C',\n",
              "                                                                              'Q']]))]),\n",
              "                                 ['Embarked'])])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqKWmhvW-jXR"
      },
      "source": [
        "# ['NameParts', 'Title', 'Comrades', 'CabinLvl', 'Social']"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReXMF1r6Gljt"
      },
      "source": [
        "s_all_cols = ['Age', 'Fare']\n",
        "s_pass = ['NameParts', 'Title', 'Comrades', 'CabinLvl', 'Social', 'Pclass', 'SibSp', 'Parch']\n",
        "s_add = ['NameParts', 'Title', 'Comrades', 'CabinLvl' ,'Social']\n",
        "\n",
        "processing_pipeline = Pipeline(\n",
        "    [\n",
        "    ('add_collumns', AdditionalCollumnsAdder(s_add)), \n",
        "    ('transform', FeatureUnion(\n",
        "        transformer_list=[\n",
        "                  ('categorical_pipeline', cat_pipeline),\n",
        "                  ('numerical_pipeline', make_pipeline(\n",
        "                      ColumnTransformer([\n",
        "                                         ('numerical', \n",
        "                                          Pipeline([\n",
        "                                            ('imputer', SimpleImputer(strategy='median'))\n",
        "                                          ]), \n",
        "                                          s_all_cols)\n",
        "                                         ], remainder='drop'), \n",
        "                      StandardScaler())),\n",
        "                      ('other', make_pipeline(\n",
        "                                ColumnTransformer([\n",
        "                                         ('numerical', \n",
        "                                          Pipeline([\n",
        "                                            ('imputer', SimpleImputer(strategy='median'))\n",
        "                                          ]), \n",
        "                                          s_pass),\n",
        "                                         ], remainder='drop'), \n",
        "\n",
        "                      ))\n",
        "                  ]))\n",
        "    ])"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo-y-KggORBv"
      },
      "source": [
        "q_all_cols = ['Age', 'Fare']\n",
        "q_pass = ['NameParts', 'Title', 'Comrades', 'CabinLvl', 'Social', 'Pclass', 'SibSp', 'Parch']\n",
        "q_add = ['NameParts', 'Title', 'Comrades', 'CabinLvl' ,'Social']\n",
        "\n",
        "quantile_processing_pipeline = Pipeline(\n",
        "    [\n",
        "    ('add_collumns', AdditionalCollumnsAdder(q_add)), \n",
        "    ('transform', FeatureUnion(\n",
        "        transformer_list=[\n",
        "                  ('categorical_pipeline', cat_pipeline),\n",
        "                  ('numerical_pipeline', make_pipeline(\n",
        "                      ColumnTransformer([\n",
        "                                         ('numerical', \n",
        "                                          Pipeline([\n",
        "                                            ('imputer', SimpleImputer(strategy='median'))\n",
        "                                          ]), \n",
        "                                          q_all_cols)\n",
        "                                         ], remainder='drop'), \n",
        "                      QuantileTransformer())),\n",
        "                      ('other', make_pipeline(\n",
        "                                ColumnTransformer([\n",
        "                                         ('numerical', \n",
        "                                          Pipeline([\n",
        "                                            ('imputer', SimpleImputer(strategy='median'))\n",
        "                                          ]), \n",
        "                                          q_pass),\n",
        "                                         ], remainder='drop'), \n",
        "\n",
        "                      ))\n",
        "                  ]))\n",
        "    ])"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azbMMLeHNvWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b965a53d-6bee-426d-dd1b-4ec032805c54"
      },
      "source": [
        "quantile_processing_pipeline.fit_transform(train_data)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.49085795, ..., 3.        , 8.        ,\n",
              "        2.        ],\n",
              "       [1.        , 1.        , 0.49085795, ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.        , 0.16455696, ..., 3.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [1.        , 0.        , 0.80028129, ..., 3.        , 1.        ,\n",
              "        5.        ],\n",
              "       [1.        , 0.        , 0.90787623, ..., 3.        , 0.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.        , 0.99578059, ..., 1.        , 1.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHaL5UEMO5Lb"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-geqpehO6lQ"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_selection import RFE"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFDlMqciRsPu"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDiriDMKPNrs"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGyjBFIPNJa",
        "outputId": "7c39652f-5221-4990-bc6f-7d65822336e6"
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('processing', quantile_processing_pipeline),\n",
        "     ('classifier', RandomForestClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__bootstrap': [True, False],\n",
        "    'classifier__max_depth': [20, 30, 40, 60, 70, 90],\n",
        "    'classifier__max_features': [0.7, 0.9, None],\n",
        "    'classifier__min_samples_leaf': [0.2, 0.4, 0.6],\n",
        "    'classifier__min_samples_split': [4, 6, 8, 10],\n",
        "    'classifier__min_samples_leaf': [4, 6, 8],\n",
        "\n",
        "    'classifier__n_estimators': [50, 100, 200, 300, 400, 500],\n",
        "    'classifier__max_leaf_nodes': [2, 4, 8, 16, 32, 64, 128]\n",
        "}\n",
        "\n",
        "grid_1 = RandomizedSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1, n_iter=300)\n",
        "\n",
        "grid_1.fit(train_data, train_target)\n",
        "\n",
        "print(grid_1.best_params_)\n",
        "# {'classifier__n_estimators': 10, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 3, 'classifier__max_depth': 100, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 50, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 6, 'classifier__max_depth': 110, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 100, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 9, 'classifier__max_depth': 10, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 400, 'classifier__min_samples_split': 0.2, 'classifier__max_leaf_nodes': 4, 'classifier__max_features': 0.7, 'classifier__max_depth': 70, 'classifier__bootstrap': False}\n",
        "# {'classifier__n_estimators': 400, 'classifier__min_samples_split': 0.2, 'classifier__max_leaf_nodes': 16, 'classifier__max_features': 0.7, 'classifier__max_depth': 60, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 400, 'classifier__min_samples_split': 0.2, 'classifier__max_leaf_nodes': 8, 'classifier__max_features': 0.7, 'classifier__max_depth': 40, 'classifier__bootstrap': False}\n",
        "# {'classifier__n_estimators': 200, 'classifier__min_samples_split': 0.4, 'classifier__max_leaf_nodes': 64, 'classifier__max_features': 0.7, 'classifier__max_depth': 40, 'classifier__bootstrap': False}\n",
        "# {'classifier__n_estimators': 200, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 4, 'classifier__max_leaf_nodes': 32, 'classifier__max_features': 0.9, 'classifier__max_depth': 30, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 50, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 6, 'classifier__max_leaf_nodes': 64, 'classifier__max_features': 0.7, 'classifier__max_depth': 20, 'classifier__bootstrap': True}\n",
        "# {'classifier__n_estimators': 400, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_leaf_nodes': 64, 'classifier__max_features': 0.7, 'classifier__max_depth': 60, 'classifier__bootstrap': True}"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'classifier__n_estimators': 400, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_leaf_nodes': 64, 'classifier__max_features': 0.7, 'classifier__max_depth': 60, 'classifier__bootstrap': True}\n",
            "CPU times: user 34.4 s, sys: 647 ms, total: 35.1 s\n",
            "Wall time: 10min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em0Wl_IjPVVs"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Im_B0C8NKTIT",
        "outputId": "9d6e62b6-d670-493f-9c8e-964d44015275"
      },
      "source": [
        "\"\"\"\n",
        "Pipeline(memory=None,steps=[('processing',Pipeline(memory=None,steps=\n",
        "[('add_collumns',AdditionalCollumnsAdder(features=['Title','Comrades','CabinLvl'])),\n",
        "('transform',FeatureUnion(n_jobs=None,transformer_list=[('categorical_pipeline',ColumnTransformer\n",
        "(n_jobs=None,remainder='drop',sparse_threshold=0.3,transformer_weights=None,transformers\n",
        "=[('Sex_enco...XGBClassifier(base_score=0.5,booster='gbtree',colsample_bylevel=1,\n",
        "colsample_bynode=1,colsample_bytree=1.0,gamma=0.2,learning_rate=0.1,max_delta_step=0,max_depth=4\n",
        ",min_child_weight=5,missing=None,n_estimators=100,n_jobs=1,nthread=None,objective='binary:logistic',\n",
        "random_state=0,reg_alpha=0,\n",
        "reg_lambda=1,scale_pos_weight=1,seed=None,silent=None,subsample=1.0,verbosity=1))],verbose=False)\n",
        "\"\"\""
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nPipeline(memory=None,steps=[('processing',Pipeline(memory=None,steps=\\n[('add_collumns',AdditionalCollumnsAdder(features=['Title','Comrades','CabinLvl'])),\\n('transform',FeatureUnion(n_jobs=None,transformer_list=[('categorical_pipeline',ColumnTransformer\\n(n_jobs=None,remainder='drop',sparse_threshold=0.3,transformer_weights=None,transformers\\n=[('Sex_enco...XGBClassifier(base_score=0.5,booster='gbtree',colsample_bylevel=1,\\ncolsample_bynode=1,colsample_bytree=1.0,gamma=0.2,learning_rate=0.1,max_delta_step=0,max_depth=4\\n,min_child_weight=5,missing=None,n_estimators=100,n_jobs=1,nthread=None,objective='binary:logistic',\\nrandom_state=0,reg_alpha=0,\\nreg_lambda=1,scale_pos_weight=1,seed=None,silent=None,subsample=1.0,verbosity=1))],verbose=False)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1DLEZPpO7KT",
        "outputId": "7ac34994-54b4-4509-e38e-3df8a48ffd53"
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('processing', quantile_processing_pipeline),\n",
        "    #  ('pca', PCA()),\n",
        "    #  ('rfe', RFE(estimator=XGBClassifier())),\n",
        "     ('classifier', XGBClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "        'classifier__min_child_weight': [1, 5, 10],\n",
        "        'classifier__gamma': [0.01, 0.2, 0.5, 1, 1.5, 2, 5],\n",
        "        'classifier__subsample': [0.2, 0.4, 0.6, 0.8, 1.0, 5.0, 10],\n",
        "        'classifier__colsample_bytree': [0.6, 0.8, 0.9,  1.0],\n",
        "        'classifier__colsample_bylevel': [0.6, 0.8, 0.9, 1.0],\n",
        "        'classifier__max_depth': [3, 4, 5],\n",
        "        'classifier__learning_rate': [1, 0.1, 0.01]\n",
        "}\n",
        "\n",
        "grid_2 = RandomizedSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1, n_iter=300)\n",
        "\n",
        "grid_2.fit(train_data, train_target)\n",
        "\n",
        "print(grid_2.best_params_)\n",
        "\n",
        "# {'classifier__subsample': 0.6, 'classifier__min_child_weight': 1, 'classifier__max_depth': 4, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 1.0}\n",
        "# {'classifier__subsample': 0.8, 'classifier__min_child_weight': 1, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 1.0, 'classifier__colsample_bylevel': 0.6}\n",
        "# {'classifier__subsample': 1.0, 'classifier__min_child_weight': 1, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.01, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.9, 'classifier__colsample_bylevel': 0.9}\n",
        "# {'classifier__subsample': 0.8, 'classifier__min_child_weight': 1, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__gamma': 2, 'classifier__colsample_bytree': 0.9, 'classifier__colsample_bylevel': 1.0}\n",
        "# {'classifier__subsample': 1.0, 'classifier__min_child_weight': 5, 'classifier__max_depth': 5, 'classifier__learning_rate': 1, 'classifier__gamma': 1, 'classifier__colsample_bytree': 0.9, 'classifier__colsample_bylevel': 1.0}\n",
        "# {'classifier__subsample': 0.8, 'classifier__min_child_weight': 10, 'classifier__max_depth': 4, 'classifier__learning_rate': 1, 'classifier__gamma': 0.01, 'classifier__colsample_bytree': 1.0, 'classifier__colsample_bylevel': 0.8}\n",
        "# {'classifier__subsample': 0.4, 'classifier__min_child_weight': 1, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.1, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.9, 'classifier__colsample_bylevel': 0.6}"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
            "{'classifier__subsample': 0.4, 'classifier__min_child_weight': 1, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.1, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.9, 'classifier__colsample_bylevel': 0.6}\n",
            "CPU times: user 19.8 s, sys: 248 ms, total: 20.1 s\n",
            "Wall time: 1min 32s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.78785581        nan        nan        nan 0.79635576 0.82298828\n",
            " 0.80474737 0.82580518        nan 0.81313897 0.79210086        nan\n",
            " 0.83003053 0.79352901 0.80894317 0.81734463 0.80331922 0.77939525\n",
            " 0.79633606 0.80470797        nan 0.79913326 0.81034177        nan\n",
            " 0.82721363        nan        nan        nan 0.81591648        nan\n",
            " 0.7766473         nan        nan 0.79210086 0.76683739 0.78926426\n",
            "        nan 0.76824584 0.81594603        nan        nan 0.75842608\n",
            "        nan        nan 0.81174037 0.80471782 0.80617551 0.81175022\n",
            " 0.82718408        nan 0.7808825         nan 0.82014183 0.81595588\n",
            " 0.77807545        nan 0.81452773 0.78510785 0.81735448 0.77807545\n",
            "        nan        nan        nan        nan        nan 0.82296858\n",
            "        nan 0.78221215 0.7808825         nan 0.80331922 0.79214025\n",
            "        nan 0.82294888 0.81877278 0.82020093 0.79493746 0.79492761\n",
            " 0.80052201        nan 0.785098          nan 0.78790505 0.81876293\n",
            " 0.77947405        nan 0.81877278 0.80892347 0.81454742 0.82437703\n",
            " 0.74566138        nan 0.81592633        nan        nan 0.79631636\n",
            " 0.82158968 0.82301783 0.82438688        nan        nan        nan\n",
            " 0.78089235        nan 0.81174037 0.79349946 0.81880232        nan\n",
            " 0.81596572 0.7850586  0.82013198        nan 0.7808825  0.77665715\n",
            " 0.80331922 0.77104304 0.80334876 0.79910371 0.7864572  0.79628681\n",
            " 0.78087265 0.83000098        nan        nan        nan 0.80749532\n",
            " 0.83002068 0.78508815 0.7878755         nan 0.81877278 0.79917266\n",
            "        nan 0.78504875 0.7836797         nan 0.7879149  0.80331922\n",
            "        nan 0.82015168 0.79070226        nan 0.7808037         nan\n",
            " 0.7780656  0.80754457 0.81032207 0.7823008  0.80053186 0.78506845\n",
            "        nan 0.82154043 0.81311928 0.80055156 0.77807545 0.81596572\n",
            " 0.78087265 0.81313897 0.79907417 0.82158968 0.79070226 0.82579533\n",
            "        nan        nan 0.81589678 0.80193046 0.80333891 0.82016153\n",
            " 0.81033192 0.79072195 0.79487836 0.80615582        nan        nan\n",
            "        nan 0.78225155 0.77805575 0.81034177 0.81876293 0.74291342\n",
            "        nan 0.80331922        nan        nan 0.79488821 0.75844578\n",
            " 0.81175022 0.77104304 0.78229095 0.81735448        nan 0.7808431\n",
            " 0.81596572        nan 0.82156013 0.81035162        nan 0.7892938\n",
            " 0.75836699        nan        nan        nan 0.81735448        nan\n",
            "        nan 0.81038117 0.78225155        nan 0.80471782        nan\n",
            " 0.82016153 0.77385009 0.82156013 0.74298237 0.81035162 0.82578548\n",
            " 0.82581503        nan 0.81172067 0.81172067 0.79629666        nan\n",
            " 0.77251059        nan 0.81878263 0.77384024 0.80891362 0.82156998\n",
            " 0.76963459        nan 0.7780262  0.82158968 0.78785581 0.80897272\n",
            "        nan 0.80613612        nan        nan 0.80753472 0.82717423\n",
            "        nan        nan 0.7766473         nan        nan 0.81173052\n",
            " 0.80190092        nan 0.78650645 0.81311928 0.82024032 0.75842608\n",
            " 0.79775436 0.78225155 0.82439673 0.80755442 0.81596572 0.82018123\n",
            " 0.80192061        nan        nan 0.79212056 0.77807545        nan\n",
            "        nan 0.82018123 0.80617551        nan 0.82578548 0.81596572\n",
            "        nan 0.81173052        nan        nan 0.80191077 0.80609672\n",
            " 0.81172067 0.80474737 0.79350931 0.79916281 0.81737418 0.74853738\n",
            " 0.76821629 0.80336846        nan 0.79774451        nan 0.77384024\n",
            " 0.80473752 0.77952329 0.7765291  0.77663745 0.81315867 0.82158968\n",
            " 0.81731508        nan 0.80895302 0.83000098 0.81034177 0.79208116]\n",
            "  category=UserWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNbW1X1sPh4b"
      },
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7am9X7cO_Cu",
        "outputId": "329fc451-401f-4541-ffef-16b90a452fe5"
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('processing', quantile_processing_pipeline),\n",
        "    #  ('pca', PCA()),\n",
        "     ('rfe', RFE(estimator=AdaBoostClassifier())),\n",
        "     ('classifier', AdaBoostClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [600, 700, 800],\n",
        "    'classifier__learning_rate': [1, 0.1, 0.01, 0.001],\n",
        "    'classifier__algorithm': ['SAMME', 'SAMME.R']\n",
        "}\n",
        "\n",
        "grid_3 = GridSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1)\n",
        "\n",
        "grid_3.fit(train_data, train_target)\n",
        "\n",
        "print(grid_3.best_params_)\n",
        "# {'classifier__n_estimators': 300, 'classifier__learning_rate': 1, 'classifier__algorithm': 'SAMME.R'}\n",
        "# {'classifier__algorithm': 'SAMME', 'classifier__learning_rate': 1, 'classifier__n_estimators': 400}\n",
        "# {'classifier__algorithm': 'SAMME', 'classifier__learning_rate': 1, 'classifier__n_estimators': 700}"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'classifier__algorithm': 'SAMME', 'classifier__learning_rate': 1, 'classifier__n_estimators': 700}\n",
            "CPU times: user 4.66 s, sys: 129 ms, total: 4.79 s\n",
            "Wall time: 2min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DagkJsJg-mCM"
      },
      "source": [
        "## K nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHKaKTtsA13K"
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('processing', processing_pipeline),\n",
        "    #  ('pca', PCA()),\n",
        "    #  ('rfe', RFE(estimator=KNeighborsClassifier())),\n",
        "     ('classifier', KNeighborsClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_neighbors': [5, 10, 15, 20, 25],\n",
        "    'classifier__weights': ['uniform', 'distance'],\n",
        "    'classifier__leaf_size': [4, 6, 8, 16],\n",
        "    'classifier__p': [1, 2, 3, 4],\n",
        "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "grid_4 = RandomizedSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1, n_iter=100)\n",
        "\n",
        "grid_4.fit(train_data, train_target)\n",
        "\n",
        "print(grid_4.best_params_)\n",
        "# {'classifier__weights': 'uniform', 'classifier__p': 1, 'classifier__n_neighbors': 15, 'classifier__leaf_size': 4, 'classifier__algorithm': 'kd_tree'}\n",
        "# {'classifier__weights': 'uniform', 'classifier__p': 1, 'classifier__n_neighbors': 20, 'classifier__leaf_size': 4, 'classifier__algorithm': 'brute'}\n",
        "# {'classifier__weights': 'uniform', 'classifier__p': 1, 'classifier__n_neighbors': 15, 'classifier__leaf_size': 6, 'classifier__algorithm': 'auto'}\n",
        "# {'classifier__weights': 'uniform', 'classifier__p': 1, 'classifier__n_neighbors': 5, 'classifier__leaf_size': 16, 'classifier__algorithm': 'kd_tree'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEzg0_YkY--Q"
      },
      "source": [
        "### Naive Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "allgynVUY90-"
      },
      "source": [
        "%%time\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('processing', processing_pipeline),\n",
        "    #  ('rfe', RFE(estimator=GaussianNB())),\n",
        "     ('classifier', GaussianNB())\n",
        "    ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__var_smoothing': [1.9e-61, 1.95e-61, 2e-61]\n",
        "\n",
        "}\n",
        "\n",
        "grid_5 = RandomizedSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1, n_iter=100)\n",
        "\n",
        "grid_5.fit(train_data, train_target)\n",
        "\n",
        "print(grid_5.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crqeuZILiW7N"
      },
      "source": [
        "### Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOH8L58mO-7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe817409-a2f5-4a18-fe47-eb156399515f"
      },
      "source": [
        "%%time\n",
        "pipe = VotingClassifier(\n",
        "    estimators=[\n",
        "                ('RandomForest', grid_1.best_estimator_), \n",
        "                ('XGBoost', grid_2.best_estimator_)\n",
        "                ]\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'estimators': [\n",
        "                [\n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('AdaBoost', grid_3.best_estimator_),\n",
        "                  ('KNearestNeighbours', grid_4.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('RandomForest', grid_1.best_estimator_), \n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('AdaBoost', grid_3.best_estimator_),\n",
        "                ],\n",
        "                [\n",
        "                  ('RandomForest', grid_1.best_estimator_), \n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('KNearestNeighbours', grid_4.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('RandomForest', grid_1.best_estimator_), \n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('AdaBoost', grid_3.best_estimator_),\n",
        "                  ('KNearestNeighbours', grid_4.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('RandomForest', grid_1.best_estimator_), \n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('AdaBoost', grid_3.best_estimator_),\n",
        "                  ('KNearestNeighbours', grid_4.best_estimator_),\n",
        "                  ('NaiveBayes', grid_5.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('KNearestNeighbours', grid_4.best_estimator_),\n",
        "                  ('NaiveBayes', grid_5.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('RandomForest', grid_1.best_estimator_), \n",
        "                  ('NaiveBayes', grid_5.best_estimator_)\n",
        "                ],\n",
        "                [\n",
        "                  ('XGBoost', grid_2.best_estimator_), \n",
        "                  ('RandomForest', grid_1.best_estimator_)\n",
        "                ]\n",
        "    ],\n",
        "    'voting': ['soft', 'hard']\n",
        "}\n",
        "\n",
        "grid_6 = GridSearchCV(pipe, param_grid, cv=kfold, verbose=10, n_jobs=-1)\n",
        "\n",
        "grid_6.fit(train_data, train_target)\n",
        "\n",
        "print(grid_6.best_params_)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (712). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'estimators': [('XGBoost', Pipeline(steps=[('processing',\n",
            "                 Pipeline(steps=[('add_collumns',\n",
            "                                  AdditionalCollumnsAdder(features=['NameParts',\n",
            "                                                                    'Title',\n",
            "                                                                    'Comrades',\n",
            "                                                                    'CabinLvl',\n",
            "                                                                    'Social'])),\n",
            "                                 ('transform',\n",
            "                                  FeatureUnion(transformer_list=[('categorical_pipeline',\n",
            "                                                                  ColumnTransformer(transformers=[('Sex_encoding',\n",
            "                                                                                                   Pipeline(steps=[('missing',\n",
            "                                                                                                                    MostFrequentImputer()),\n",
            "                                                                                                                   ('lab',\n",
            "                                                                                                                    OrdinalEncoder())]),\n",
            "                                                                                                   ['Sex']...\n",
            "                                                                 ('other',\n",
            "                                                                  Pipeline(steps=[('columntransformer',\n",
            "                                                                                   ColumnTransformer(transformers=[('numerical',\n",
            "                                                                                                                    Pipeline(steps=[('imputer',\n",
            "                                                                                                                                     SimpleImputer(strategy='median'))]),\n",
            "                                                                                                                    ['NameParts',\n",
            "                                                                                                                     'Title',\n",
            "                                                                                                                     'Comrades',\n",
            "                                                                                                                     'CabinLvl',\n",
            "                                                                                                                     'Social',\n",
            "                                                                                                                     'Pclass',\n",
            "                                                                                                                     'SibSp',\n",
            "                                                                                                                     'Parch'])]))]))]))])),\n",
            "                ('classifier',\n",
            "                 XGBClassifier(colsample_bylevel=0.6, colsample_bytree=0.9,\n",
            "                               gamma=0.2, max_depth=4, subsample=0.4))])), ('RandomForest', Pipeline(steps=[('processing',\n",
            "                 Pipeline(steps=[('add_collumns',\n",
            "                                  AdditionalCollumnsAdder(features=['NameParts',\n",
            "                                                                    'Title',\n",
            "                                                                    'Comrades',\n",
            "                                                                    'CabinLvl',\n",
            "                                                                    'Social'])),\n",
            "                                 ('transform',\n",
            "                                  FeatureUnion(transformer_list=[('categorical_pipeline',\n",
            "                                                                  ColumnTransformer(transformers=[('Sex_encoding',\n",
            "                                                                                                   Pipeline(steps=[('missing',\n",
            "                                                                                                                    MostFrequentImputer()),\n",
            "                                                                                                                   ('lab',\n",
            "                                                                                                                    OrdinalEncoder())]),\n",
            "                                                                                                   ['Sex']...\n",
            "                                                                  Pipeline(steps=[('columntransformer',\n",
            "                                                                                   ColumnTransformer(transformers=[('numerical',\n",
            "                                                                                                                    Pipeline(steps=[('imputer',\n",
            "                                                                                                                                     SimpleImputer(strategy='median'))]),\n",
            "                                                                                                                    ['NameParts',\n",
            "                                                                                                                     'Title',\n",
            "                                                                                                                     'Comrades',\n",
            "                                                                                                                     'CabinLvl',\n",
            "                                                                                                                     'Social',\n",
            "                                                                                                                     'Pclass',\n",
            "                                                                                                                     'SibSp',\n",
            "                                                                                                                     'Parch'])]))]))]))])),\n",
            "                ('classifier',\n",
            "                 RandomForestClassifier(max_depth=60, max_features=0.7,\n",
            "                                        max_leaf_nodes=64, min_samples_leaf=4,\n",
            "                                        min_samples_split=10,\n",
            "                                        n_estimators=400))]))], 'voting': 'hard'}\n",
            "CPU times: user 45.3 s, sys: 582 ms, total: 45.9 s\n",
            "Wall time: 3min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJSbDYBNiySP"
      },
      "source": [
        "# Compare results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCglI_2AO-4J",
        "outputId": "678c1250-4af3-49eb-9d76-b01d9684c501"
      },
      "source": [
        "from sklearn import  metrics\n",
        "\n",
        "\n",
        "models = []\n",
        "models.append(('Random Forest', grid_1.best_estimator_))\n",
        "models.append(('XGBoost', grid_2.best_estimator_))\n",
        "models.append(('AdaBoost', grid_3.best_estimator_))\n",
        "models.append(('KNearestNeighbors', grid_4.best_estimator_))\n",
        "models.append(('NaiveBayes', grid_5.best_estimator_))\n",
        "models.append(('Voting', grid_6.best_estimator_))\n",
        "\n",
        "models_names = [name for name, m in models]\n",
        "\n",
        "precision_score = []\n",
        "recall_score = []\n",
        "f1_score = []\n",
        "accuracy_score = []\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    print(\"precision_score: {}\".format(metrics.precision_score(validate_target, model.predict(validate_data)) ))\n",
        "    print(\"recall_score: {}\".format( metrics.recall_score(validate_target, model.predict(validate_data)) ))\n",
        "    print(\"f1_score: {}\".format( metrics.f1_score(validate_target, model.predict(validate_data)) ))\n",
        "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(validate_target, model.predict(validate_data)) ))\n",
        "    precision_score.append(metrics.precision_score(validate_target, model.predict(validate_data)))\n",
        "    recall_score.append(metrics.recall_score(validate_target, model.predict(validate_data)))\n",
        "    f1_score.append( metrics.f1_score(validate_target, model.predict(validate_data)))\n",
        "    accuracy_score.append(metrics.accuracy_score(validate_target, model.predict(validate_data)))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "precision_score: 0.9180327868852459\n",
            "recall_score: 0.8615384615384616\n",
            "f1_score: 0.8888888888888888\n",
            "accuracy_score: 0.9217877094972067\n",
            "XGBoost\n",
            "precision_score: 0.9122807017543859\n",
            "recall_score: 0.8\n",
            "f1_score: 0.8524590163934427\n",
            "accuracy_score: 0.8994413407821229\n",
            "AdaBoost\n",
            "precision_score: 0.8360655737704918\n",
            "recall_score: 0.7846153846153846\n",
            "f1_score: 0.8095238095238095\n",
            "accuracy_score: 0.8659217877094972\n",
            "KNearestNeighbors\n",
            "precision_score: 0.8679245283018868\n",
            "recall_score: 0.7076923076923077\n",
            "f1_score: 0.7796610169491526\n",
            "accuracy_score: 0.8547486033519553\n",
            "NaiveBayes\n",
            "precision_score: 0.7301587301587301\n",
            "recall_score: 0.7076923076923077\n",
            "f1_score: 0.7187500000000001\n",
            "accuracy_score: 0.7988826815642458\n",
            "Voting\n",
            "precision_score: 0.8936170212765957\n",
            "recall_score: 0.6461538461538462\n",
            "f1_score: 0.75\n",
            "accuracy_score: 0.8435754189944135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "fmKPTw9NO-qk",
        "outputId": "dd8ac89c-49cd-4ce0-fa98-ce6cb7d6b659"
      },
      "source": [
        "import pandas as pd\n",
        "d = {'precision_score': precision_score, \n",
        "     'recall_score': recall_score, \n",
        "     'f1_score': f1_score,\n",
        "     'accuracy_score' : accuracy_score\n",
        "    }\n",
        "df = pd.DataFrame(data=d)\n",
        "df.insert(loc=0, column='Method', value=models_names)\n",
        "df"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>accuracy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.921788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0.899441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.784615</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.865922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNearestNeighbors</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.779661</td>\n",
              "      <td>0.854749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaiveBayes</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.798883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Voting</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.843575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Method  precision_score  recall_score  f1_score  accuracy_score\n",
              "0      Random Forest         0.918033      0.861538  0.888889        0.921788\n",
              "1            XGBoost         0.912281      0.800000  0.852459        0.899441\n",
              "2           AdaBoost         0.836066      0.784615  0.809524        0.865922\n",
              "3  KNearestNeighbors         0.867925      0.707692  0.779661        0.854749\n",
              "4         NaiveBayes         0.730159      0.707692  0.718750        0.798883\n",
              "5             Voting         0.893617      0.646154  0.750000        0.843575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWR552mjEui",
        "outputId": "ae26b7e4-8d37-449d-b937-cc6aac6394ed"
      },
      "source": [
        "model = grid_6.best_estimator_\n",
        "model.fit(pd.concat((train_data, validate_data)), pd.concat((train_target, validate_target)))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (891). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2615: UserWarning: n_quantiles (1000) is greater than the total number of samples (891). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('XGBoost',\n",
              "                              Pipeline(steps=[('processing',\n",
              "                                               Pipeline(steps=[('add_collumns',\n",
              "                                                                AdditionalCollumnsAdder(features=['NameParts',\n",
              "                                                                                                  'Title',\n",
              "                                                                                                  'Comrades',\n",
              "                                                                                                  'CabinLvl',\n",
              "                                                                                                  'Social'])),\n",
              "                                                               ('transform',\n",
              "                                                                FeatureUnion(transformer_list=[('categorical_pipeline',\n",
              "                                                                                                ColumnTransformer(transformers=[('Sex_encoding',\n",
              "                                                                                                                                 Pipeline(steps=[('missing',\n",
              "                                                                                                                                                  MostFrequentImput...\n",
              "                                                                                                Pipeline(steps=[('columntransformer',\n",
              "                                                                                                                 ColumnTransformer(transformers=[('numerical',\n",
              "                                                                                                                                                  Pipeline(steps=[('imputer',\n",
              "                                                                                                                                                                   SimpleImputer(strategy='median'))]),\n",
              "                                                                                                                                                  ['NameParts',\n",
              "                                                                                                                                                   'Title',\n",
              "                                                                                                                                                   'Comrades',\n",
              "                                                                                                                                                   'CabinLvl',\n",
              "                                                                                                                                                   'Social',\n",
              "                                                                                                                                                   'Pclass',\n",
              "                                                                                                                                                   'SibSp',\n",
              "                                                                                                                                                   'Parch'])]))]))]))])),\n",
              "                                              ('classifier',\n",
              "                                               RandomForestClassifier(max_depth=60,\n",
              "                                                                      max_features=0.7,\n",
              "                                                                      max_leaf_nodes=64,\n",
              "                                                                      min_samples_leaf=4,\n",
              "                                                                      min_samples_split=10,\n",
              "                                                                      n_estimators=400))]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NLwBBNbtjNw2",
        "outputId": "b9c19f04-017f-4bcf-e9dd-0dff39c04efe"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9oHfjsCnG9V",
        "outputId": "2b15f516-9920-4068-e30a-0618133cf96d"
      },
      "source": [
        "test_results = model.predict(test_data)\n",
        "test_results"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVDwKL9YnHwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0679fc0-b44c-48a2-b811-cddc822cbf04"
      },
      "source": [
        "(test_results == 0).sum(), (test_results == 1).sum()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(273, 145)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vcbco62nMl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "08b465bd-97c6-46cd-911a-593dc9bab13f"
      },
      "source": [
        "output = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': test_results})\n",
        "output.head()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsT-AbDWrXv2"
      },
      "source": [
        "output.to_csv('output.csv', index=False)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUJwHtl3rarI"
      },
      "source": [
        "# 0.78708"
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}